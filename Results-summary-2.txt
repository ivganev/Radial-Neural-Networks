 
####################################
###### Comparison results ##########
####################################

Learning rate is always 0.05 for both.
###############################

seed=1
n = 3
m= 1000

Over 10 trials, each training for 100 epochs:

Radnet Loss = 3.910e-03 +/- 3.232e-05
Radnet Accuracy = 1.000e+00 +/- 0.000e+00
ReLU MLP Loss = 3.111e-01 +/- 2.889e-01
ReLU MLP Accuracy = 9.213e-01 +/- 2.490e-01


Over 10 trials, each training for 100 epochs:

Radnet Loss = 3.913e-03 +/- 3.335e-05
Radnet Accuracy = 1.000e+00 +/- 0.000e+00
ReLU MLP Loss = 3.241e-01 +/- 2.915e-01
ReLU MLP Accuracy = 9.333e-01 +/- 2.108e-01

Over 10 trials, each training for 100 epochs:

Radnet Loss = 0.00547 +/- 3.837e-05
Radnet Accuracy = 1 +/- 0.000e+00
ReLU MLP Loss = 0.449 +/- 2.066e-01
ReLU MLP Accuracy = 0.859 +/- 1.671e-01
##############################

see=2
number or original images = 3
number of copies of each = 100
number or samples = 240 train, 60 test
dimension vector = [784, 785, 786, 3]

RadNet train_loss = 0.00291 +/- 4.019e-04
RadNet train_accuracy = 1 +/- 0.000e+00
RadNet test_loss = 0.0031 +/- 4.848e-04
RadNet test_accuracy = 1 +/- 0.000e+00
ReLU MLP train_loss = 0.227 +/- 2.557e-01
ReLU MLP train_accuracy = 0.862 +/- 1.782e-01
ReLU MLP test_loss = 0.214 +/- 2.581e-01
ReLU MLP test_accuracy = 0.88 +/- 1.583e-01

##############################

n=3
m=1000

Over 10 trials, each training for 50 epochs:

Radnet Loss = 1.671e-02 +/- 1.908e-04
Radnet Accuracy = 1.000e+00 +/- 0.000e+00
ReLU MLP Loss = 6.803e-01 +/- 2.244e-01
ReLU MLP Accuracy = 7.391e-01 +/- 2.382e-01


##############################

n=3
m=1000

Over 10 trials, each training for 100 epochs:

Radnet Loss = 0.00557 +/- 3.011e-05
Radnet Accuracy = 1 +/- 0.000e+00
ReLU MLP Loss = 0.382e +/- 3.090e-01
ReLU MLP Accuracy = 0.869 +/- 2.310e-01



####################################
###### Batch of all of MNIST results
####################################

Seems like relu does better overall

batch of MNIST of size 128
learning rate is 0.05 for both

Radnet:
Epoch 1, Loss 2.304385, Accuracy 0.093750
Epoch 500, Loss 1.627689, Accuracy 0.851562
Epoch 1000, Loss 0.915896, Accuracy 0.992188
Epoch 1500, Loss 0.474702, Accuracy 1.000000
Epoch 2000, Loss 0.270006, Accuracy 1.000000
Epoch 2500, Loss 0.175651, Accuracy 1.000000
Epoch 3000, Loss 0.126336, Accuracy 1.

ReLU net:
Epoch 1, Loss 2.304423, Accuracy 0.085938
Epoch 500, Loss 0.020677, Accuracy 1.000000
Epoch 1000, Loss 0.003984, Accuracy 1.000000
Epoch 1500, Loss 0.001949, Accuracy 1.000000
Epoch 2000, Loss 0.001237, Accuracy 1.000000
Epoch 2500, Loss 0.000887, Accuracy 1.000000
Epoch 3000, Loss 0.000683, Accuracy 1.000000


Radnet:
Epoch 1, Loss 2.300568, Accuracy 0.070312
Epoch 500, Loss 1.618979, Accuracy 0.796875
Epoch 1000, Loss 0.898146, Accuracy 0.992188
Epoch 1500, Loss 0.471940, Accuracy 1.000000
Epoch 2000, Loss 0.271410, Accuracy 1.000000
Epoch 2500, Loss 0.176950, Accuracy 1.000000
Epoch 3000, Loss 0.127200, Accuracy 1.000000


ReLU net:
Epoch 1, Loss 2.305037, Accuracy 0.070312
Epoch 500, Loss 0.016815, Accuracy 1.000000
Epoch 1000, Loss 0.003802, Accuracy 1.000000
Epoch 1500, Loss 0.001919, Accuracy 1.000000
Epoch 2000, Loss 0.001233, Accuracy 1.000000
Epoch 2500, Loss 0.000889, Accuracy 1.000000
Epoch 3000, Loss 0.000687, Accuracy 1.000000


Radnet:
Epoch 1, Loss 2.301806, Accuracy 0.093750
Epoch 500, Loss 1.594446, Accuracy 0.851562
Epoch 1000, Loss 0.909879, Accuracy 0.984375
Epoch 1500, Loss 0.486431, Accuracy 1.000000
Epoch 2000, Loss 0.281883, Accuracy 1.000000
Epoch 2500, Loss 0.184295, Accuracy 1.000000
Epoch 3000, Loss 0.132537, Accuracy 1.000000

ReLU net:
Epoch 1, Loss 2.299549, Accuracy 0.109375
Epoch 500, Loss 0.016571, Accuracy 1.000000
Epoch 1000, Loss 0.003563, Accuracy 1.000000
Epoch 1500, Loss 0.001777, Accuracy 1.000000
Epoch 2000, Loss 0.001135, Accuracy 1.000000
Epoch 2500, Loss 0.000817, Accuracy 1.000000
Epoch 3000, Loss 0.000630, Accuracy 1.000000


