{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advanced-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from source import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-azerbaijan",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medical-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step RelU\n",
    "# Version for the eta in the definition of a radial rescaling activation\n",
    "\n",
    "def stepReLU_eta(r):\n",
    "    if r.shape == torch.Size([]):\n",
    "        if r < 1:\n",
    "            return 1e-6\n",
    "        return r\n",
    "    else:\n",
    "        for i in range(len(r)):\n",
    "            if r[i] < 1:\n",
    "                r[i] = 1e-6\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opponent-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create uniform random noise in the unit d-ball\n",
    "def generate_noise(m, r, d=28*28):\n",
    "    '''m is the number of samples, r is the radius\n",
    "    d is the total dimension, which is 28*28 for MNIST'''\n",
    "    \n",
    "    u = np.random.multivariate_normal(np.zeros(d),np.eye(d),m)  # an array of d normally distributed random variables\n",
    "    norm=np.sum(u**2, axis = 1) **(0.5)\n",
    "    norm = norm.reshape(m,1)\n",
    "    rands = np.random.uniform(size=m)**(1.0/d)\n",
    "    rands = rands.reshape(m,1)\n",
    "    return r*rands*u/norm\n",
    "\n",
    "# Note: need to do the following before adding to a sample:\n",
    "# torch.tensor(generate_noise(m,radius,d)).reshape(m,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "czech-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "def smallest_distance(x: torch.tensor) -> float:\n",
    "    radius = float('inf')\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i):\n",
    "            if torch.linalg.norm(x[i] - x[j]).item() < radius:\n",
    "                radius = torch.linalg.norm(x[i] - x[j]).item()\n",
    "    return radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sixth-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "def shortest_distances(x: torch.tensor) -> list:\n",
    "    result = []\n",
    "    for i in range(len(x)):\n",
    "        radius = float('inf')\n",
    "        for j in range(i):\n",
    "            if torch.linalg.norm(x[i] - x[j]).item() < radius:\n",
    "                radius = torch.linalg.norm(x[i] - x[j]).item()\n",
    "        for j in range(i+1,len(x)):\n",
    "            if torch.linalg.norm(x[i] - x[j]).item() < radius:\n",
    "                radius = torch.linalg.norm(x[i] - x[j]).item()\n",
    "        result.append(radius)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "running-three",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 2.0, 4.0, 20.0, 0.5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_distances(torch.tensor([3.,5.,9.,29., 2.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-finder",
   "metadata": {},
   "source": [
    "# Get MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "separated-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "animated-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(training_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decreased-police",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([128, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "if False:\n",
    "    img = train_features[0].squeeze()\n",
    "    label = train_labels[0]\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-offering",
   "metadata": {},
   "source": [
    "# Select threes and add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endangered-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the threes\n",
    "def add_noise(label, n=5, m=100, verbose=False):\n",
    "    '''label is one of 0,1,2,3,4,5,6,7,8,9;\n",
    "    n is the number of original images; \n",
    "    m is the number of noisy samples per original image;\n",
    "    may want to make the 2.5 definition of the radius into a hyperparameter\n",
    "    '''\n",
    "    \n",
    "    # Get a selection of data with the same label, crop it to size n\n",
    "    selection = train_features[train_labels == label]\n",
    "    selection = selection[:n]\n",
    "    assert selection.shape[0] == n, \"Too few of this label; take another batch\"\n",
    "    if verbose:\n",
    "        plt.imshow(selection[2].squeeze(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "    \n",
    "    radii = shortest_distances(selection)\n",
    "    print(radii)\n",
    "    noise = torch.tensor(generate_noise(m,r=1,d=28*28)).reshape(m,1,28,28)\n",
    "    print(noise.flatten(1).max(), noise.flatten(1).min() )\n",
    "    \n",
    "    noisy_samples = torch.Tensor(torch.Size([int(n*m), 1, 28, 28]))\n",
    "    noisy_labels = torch.Tensor(torch.Size([n*m, n]))\n",
    "    for i in range(n):\n",
    "        radius = radii[i]/2\n",
    "        assert radius > 1e-6, \"some samples are too close together\"\n",
    "        for j in range(m):\n",
    "            noisy_samples[i*m + j]= selection[i] + radius*noise[j]   \n",
    "            noisy_labels[i*m + j]=  torch.eye(n)[i]\n",
    "    \n",
    "    if verbose:\n",
    "        plt.imshow(selection[0][0], cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(noisy_samples[0][0], cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(noisy_samples[1][0], cmap=\"gray\")\n",
    "        \n",
    "    # Need to add shuffle\n",
    "    \n",
    "    return noisy_samples, noisy_labels\n",
    "\n",
    "# Alternative for the labels:\n",
    "# torch.eye(n).repeat_interleave(m, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "southeast-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print('Enter the number of original images:')\n",
    "    num_samples = input()\n",
    "\n",
    "    print('Enter the number of noisy copies of each:')\n",
    "    m_copies = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spiritual-meditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.137116432189941, 10.164294242858887, 8.137116432189941]\n",
      "tensor(0.1265, dtype=torch.float64) tensor(-0.1276, dtype=torch.float64)\n",
      "torch.Size([30, 1, 28, 28]) torch.Size([30, 3])\n"
     ]
    }
   ],
   "source": [
    "num_samples = 3\n",
    "m_copies = 10\n",
    "\n",
    "noisy_threes, noisy_labels = add_noise(label=3, n=int(num_samples), m=int(m_copies), verbose =False)\n",
    "print(noisy_threes.shape, noisy_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "juvenile-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_threes_flat = noisy_threes.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dimensional-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.5938), tensor(-0.6482))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_threes_flat.max() , noisy_threes_flat.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-october",
   "metadata": {},
   "source": [
    "# Train radnet with the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nonprofit-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=28*28\n",
    "dim_vector = [d, d+1, d+2, d+3,num_samples]\n",
    "\n",
    "# torch.sigmoid\n",
    "\n",
    "radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sapphire-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False).to(device)\n",
    "    \n",
    "    model_trained, model_losses = training_loop(\n",
    "    n_epochs = 2000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = noisy_threes_flat.to(device),\n",
    "    y_train = noisy_labels.to(device),\n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "irish-rubber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 0.322344\n",
      "Epoch 500, Loss 0.000000\n",
      "Epoch 1000, Loss 0.000000\n",
      "Epoch 1500, Loss 0.000000\n",
      "Epoch 2000, Loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "model_trained, model_losses = training_loop(\n",
    "    n_epochs = 2000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = noisy_threes_flat,\n",
    "    y_train = noisy_labels,\n",
    "    verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-discipline",
   "metadata": {},
   "source": [
    "Cross entropy loss stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-million",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "collaborative-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_training_loop(n_epochs, learning_rate, model, params, x_train, y_train, verbose=True):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    y_classes = y_train.argmax(axis =1)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        for p in params:\n",
    "            if p.grad is not None: \n",
    "                p.grad.zero_()\n",
    "        \n",
    "        y_pred = model(x_train)\n",
    "        pred_class = torch.argmax(y_pred, dim=1)\n",
    "        accuracy = torch.mean((pred_class == y_classes).to(float))\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_function(y_pred, y_classes)\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for p in params:\n",
    "                p -= learning_rate * p.grad\n",
    "                \n",
    "        if verbose:\n",
    "            if epoch ==1 or epoch % 500 == 0:\n",
    "                print('Epoch %d, Loss %f, Accuracy %f' % (epoch, float(loss), float(accuracy)))\n",
    "\n",
    "            \n",
    "    return model, losses, accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "british-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "compliant-boating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.091792, Accuracy 0.133333\n",
      "Epoch 500, Loss 0.000395, Accuracy 1.000000\n",
      "Epoch 1000, Loss 0.000163, Accuracy 1.000000\n"
     ]
    }
   ],
   "source": [
    "model_trained, model_losses , model_accuracies = ce_training_loop(\n",
    "    n_epochs = 1000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = noisy_threes_flat,\n",
    "    y_train = noisy_labels,\n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-mystery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-robertson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-library",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "advanced-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(4, num_classes, requires_grad=True)\n",
    "target = torch.empty(4, dtype=torch.long).random_(num_classes)\n",
    "# target[k] is the index of the class of the k-th sample\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "representative-extraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.2942, -2.8373, -3.0682],\n",
      "        [ 6.5244, -3.1795, -2.9536],\n",
      "        [ 6.2014, -3.2207, -2.6157],\n",
      "        [ 6.2940, -3.1625, -2.7522],\n",
      "        [ 6.2184, -2.9116, -2.9704],\n",
      "        [ 6.5575, -3.1103, -3.0222],\n",
      "        [ 6.2379, -3.0356, -2.8065],\n",
      "        [ 6.0924, -3.1872, -2.4918],\n",
      "        [ 6.3255, -3.0138, -2.8894],\n",
      "        [ 6.4417, -3.3327, -2.7502],\n",
      "        [-2.1863,  7.1945, -5.0766],\n",
      "        [-1.8987,  6.7672, -4.9335],\n",
      "        [-2.3022,  6.7156, -4.5114],\n",
      "        [-2.1865,  6.7884, -4.6819]], grad_fn=<SliceBackward>) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = radnet(noisy_threes_flat)[:14]\n",
    "print(y_pred, noisy_labels.argmax(axis = 1)[:14])\n",
    "loss(y_pred, noisy_labels.argmax(axis = 1)[:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "educational-halifax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = torch.argmax(y_pred, dim=1)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "harmful-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = torch.mean((pred_class == noisy_labels.argmax(axis=1)[:14]).to(float))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "discrete-peoples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9/14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-chicken",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-authority",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-cyprus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-bundle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "canadian-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of target with class indices\n",
    "num_classes = 3\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(4, num_classes, requires_grad=True)\n",
    "target = torch.empty(4, dtype=torch.long).random_(num_classes)\n",
    "# target[k] is the index of the class of the k-th sample\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affecting-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4797,  0.5874,  0.0297],\n",
       "         [-1.1980,  0.3110, -0.6938],\n",
       "         [ 0.1830,  2.2177,  0.5553],\n",
       "         [ 0.3083, -0.3667, -0.6029]], requires_grad=True),\n",
       " tensor([2, 1, 1, 0]),\n",
       " tensor(0.6490, grad_fn=<NllLossBackward>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, target, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-timber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "quantitative-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1., 0., 0.], [0., 0., 1.]])\n",
    "y = torch.tensor([[13., 5., 12.], [28., 28., 33.]])\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "growing-lightning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_classes = torch.argmax(x, axis =1)\n",
    "x_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-practice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "forward-freight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_classes = x.argmax(axis =1)\n",
    "x_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-qualification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-emperor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-linux",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-thesis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-personal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-manchester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "color-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0918e+00, 1.0092e+00, 9.3315e-01, 8.5890e-01, 7.8396e-01, 7.0749e-01,\n",
      "        6.3001e-01, 5.5320e-01, 4.7945e-01, 4.1117e-01, 3.5009e-01, 2.9700e-01,\n",
      "        2.5182e-01, 2.1391e-01, 1.8241e-01, 1.5635e-01, 1.3484e-01, 1.1706e-01,\n",
      "        1.0234e-01, 9.0084e-02, 7.9835e-02, 7.1211e-02, 6.3908e-02, 5.7684e-02,\n",
      "        5.2345e-02, 4.7736e-02, 4.3734e-02, 4.0238e-02, 3.7168e-02, 3.4457e-02,\n",
      "        3.2052e-02, 2.9908e-02, 2.7989e-02, 2.6264e-02, 2.4707e-02, 2.3297e-02,\n",
      "        2.2015e-02, 2.0847e-02, 1.9779e-02, 1.8799e-02, 1.7897e-02, 1.7066e-02,\n",
      "        1.6299e-02, 1.5587e-02, 1.4927e-02, 1.4312e-02, 1.3740e-02, 1.3205e-02,\n",
      "        1.2704e-02, 1.2236e-02, 1.1796e-02, 1.1382e-02, 1.0992e-02, 1.0625e-02,\n",
      "        1.0278e-02, 9.9508e-03, 9.6406e-03, 9.3468e-03, 9.0680e-03, 8.8033e-03,\n",
      "        8.5516e-03, 8.3121e-03, 8.0839e-03, 7.8664e-03, 7.6588e-03, 7.4605e-03,\n",
      "        7.2709e-03, 7.0896e-03, 6.9159e-03, 6.7495e-03, 6.5900e-03, 6.4369e-03,\n",
      "        6.2899e-03, 6.1486e-03, 6.0127e-03, 5.8821e-03, 5.7562e-03, 5.6350e-03,\n",
      "        5.5182e-03, 5.4056e-03, 5.2969e-03, 5.1920e-03, 5.0907e-03, 4.9927e-03,\n",
      "        4.8981e-03, 4.8065e-03, 4.7179e-03, 4.6321e-03, 4.5490e-03, 4.4685e-03,\n",
      "        4.3904e-03, 4.3147e-03, 4.2413e-03, 4.1701e-03, 4.1009e-03, 4.0337e-03,\n",
      "        3.9685e-03, 3.9050e-03, 3.8434e-03, 3.7834e-03, 3.7250e-03, 3.6683e-03,\n",
      "        3.6130e-03, 3.5592e-03, 3.5067e-03, 3.4557e-03, 3.4059e-03, 3.3574e-03,\n",
      "        3.3100e-03, 3.2639e-03, 3.2189e-03, 3.1749e-03, 3.1320e-03, 3.0902e-03,\n",
      "        3.0493e-03, 3.0093e-03, 2.9703e-03, 2.9321e-03, 2.8948e-03, 2.8584e-03,\n",
      "        2.8227e-03, 2.7879e-03, 2.7538e-03, 2.7204e-03, 2.6877e-03, 2.6557e-03,\n",
      "        2.6244e-03, 2.5937e-03, 2.5637e-03, 2.5343e-03, 2.5055e-03, 2.4772e-03,\n",
      "        2.4495e-03, 2.4224e-03, 2.3958e-03, 2.3697e-03, 2.3441e-03, 2.3190e-03,\n",
      "        2.2943e-03, 2.2701e-03, 2.2464e-03, 2.2231e-03, 2.2002e-03, 2.1778e-03,\n",
      "        2.1558e-03, 2.1341e-03, 2.1129e-03, 2.0920e-03, 2.0714e-03, 2.0513e-03,\n",
      "        2.0314e-03, 2.0119e-03, 1.9928e-03, 1.9740e-03, 1.9555e-03, 1.9372e-03,\n",
      "        1.9193e-03, 1.9017e-03, 1.8844e-03, 1.8673e-03, 1.8506e-03, 1.8341e-03,\n",
      "        1.8178e-03, 1.8018e-03, 1.7861e-03, 1.7706e-03, 1.7553e-03, 1.7403e-03,\n",
      "        1.7255e-03, 1.7109e-03, 1.6966e-03, 1.6824e-03, 1.6685e-03, 1.6547e-03,\n",
      "        1.6412e-03, 1.6279e-03, 1.6147e-03, 1.6018e-03, 1.5890e-03, 1.5765e-03,\n",
      "        1.5640e-03, 1.5518e-03, 1.5397e-03, 1.5278e-03, 1.5161e-03, 1.5045e-03,\n",
      "        1.4931e-03, 1.4819e-03, 1.4707e-03, 1.4598e-03, 1.4490e-03, 1.4383e-03,\n",
      "        1.4277e-03, 1.4173e-03, 1.4071e-03, 1.3970e-03, 1.3870e-03, 1.3771e-03,\n",
      "        1.3673e-03, 1.3577e-03, 1.3482e-03, 1.3388e-03, 1.3296e-03, 1.3204e-03,\n",
      "        1.3114e-03, 1.3024e-03, 1.2936e-03, 1.2849e-03, 1.2763e-03, 1.2678e-03,\n",
      "        1.2594e-03, 1.2511e-03, 1.2429e-03, 1.2347e-03, 1.2267e-03, 1.2188e-03,\n",
      "        1.2110e-03, 1.2032e-03, 1.1956e-03, 1.1880e-03, 1.1805e-03, 1.1731e-03,\n",
      "        1.1658e-03, 1.1585e-03, 1.1514e-03, 1.1443e-03, 1.1373e-03, 1.1304e-03,\n",
      "        1.1236e-03, 1.1168e-03, 1.1101e-03, 1.1035e-03, 1.0969e-03, 1.0904e-03,\n",
      "        1.0840e-03, 1.0777e-03, 1.0714e-03, 1.0652e-03, 1.0590e-03, 1.0529e-03,\n",
      "        1.0469e-03, 1.0409e-03, 1.0350e-03, 1.0292e-03, 1.0234e-03, 1.0177e-03,\n",
      "        1.0120e-03, 1.0064e-03, 1.0009e-03, 9.9536e-04, 9.8991e-04, 9.8450e-04,\n",
      "        9.7917e-04, 9.7387e-04, 9.6861e-04, 9.6345e-04, 9.5830e-04, 9.5321e-04,\n",
      "        9.4819e-04, 9.4318e-04, 9.3824e-04, 9.3334e-04, 9.2849e-04, 9.2368e-04,\n",
      "        9.1893e-04, 9.1421e-04, 9.0953e-04, 9.0492e-04, 9.0030e-04, 8.9577e-04,\n",
      "        8.9126e-04, 8.8680e-04, 8.8235e-04, 8.7798e-04, 8.7364e-04, 8.6933e-04,\n",
      "        8.6507e-04, 8.6082e-04, 8.5662e-04, 8.5247e-04, 8.4833e-04, 8.4425e-04,\n",
      "        8.4021e-04, 8.3619e-04, 8.3221e-04, 8.2826e-04, 8.2435e-04, 8.2046e-04,\n",
      "        8.1662e-04, 8.1282e-04, 8.0904e-04, 8.0527e-04, 8.0156e-04, 7.9786e-04,\n",
      "        7.9420e-04, 7.9059e-04, 7.8698e-04, 7.8341e-04, 7.7988e-04, 7.7636e-04,\n",
      "        7.7287e-04, 7.6941e-04, 7.6600e-04, 7.6261e-04, 7.5924e-04, 7.5589e-04,\n",
      "        7.5257e-04, 7.4928e-04, 7.4601e-04, 7.4276e-04, 7.3955e-04, 7.3634e-04,\n",
      "        7.3319e-04, 7.3005e-04, 7.2693e-04, 7.2384e-04, 7.2076e-04, 7.1772e-04,\n",
      "        7.1470e-04, 7.1171e-04, 7.0872e-04, 7.0577e-04, 7.0285e-04, 6.9992e-04,\n",
      "        6.9704e-04, 6.9418e-04, 6.9133e-04, 6.8851e-04, 6.8571e-04, 6.8291e-04,\n",
      "        6.8015e-04, 6.7741e-04, 6.7469e-04, 6.7199e-04, 6.6929e-04, 6.6664e-04,\n",
      "        6.6399e-04, 6.6137e-04, 6.5877e-04, 6.5619e-04, 6.5359e-04, 6.5106e-04,\n",
      "        6.4852e-04, 6.4601e-04, 6.4351e-04, 6.4102e-04, 6.3857e-04, 6.3612e-04,\n",
      "        6.3368e-04, 6.3128e-04, 6.2887e-04, 6.2649e-04, 6.2413e-04, 6.2178e-04,\n",
      "        6.1945e-04, 6.1714e-04, 6.1483e-04, 6.1255e-04, 6.1028e-04, 6.0802e-04,\n",
      "        6.0580e-04, 6.0356e-04, 6.0134e-04, 5.9914e-04, 5.9696e-04, 5.9483e-04,\n",
      "        5.9266e-04, 5.9051e-04, 5.8839e-04, 5.8629e-04, 5.8418e-04, 5.8210e-04,\n",
      "        5.8003e-04, 5.7797e-04, 5.7594e-04, 5.7389e-04, 5.7189e-04, 5.6989e-04,\n",
      "        5.6789e-04, 5.6592e-04, 5.6394e-04, 5.6198e-04, 5.6006e-04, 5.5813e-04,\n",
      "        5.5620e-04, 5.5430e-04, 5.5241e-04, 5.5050e-04, 5.4866e-04, 5.4680e-04,\n",
      "        5.4494e-04, 5.4310e-04, 5.4128e-04, 5.3948e-04, 5.3766e-04, 5.3588e-04,\n",
      "        5.3409e-04, 5.3232e-04, 5.3055e-04, 5.2880e-04, 5.2706e-04, 5.2534e-04,\n",
      "        5.2361e-04, 5.2191e-04, 5.2020e-04, 5.1854e-04, 5.1685e-04, 5.1518e-04,\n",
      "        5.1352e-04, 5.1186e-04, 5.1024e-04, 5.0861e-04, 5.0700e-04, 5.0539e-04,\n",
      "        5.0377e-04, 5.0217e-04, 5.0060e-04, 4.9902e-04, 4.9747e-04, 4.9589e-04,\n",
      "        4.9436e-04, 4.9282e-04, 4.9128e-04, 4.8977e-04, 4.8823e-04, 4.8674e-04,\n",
      "        4.8525e-04, 4.8375e-04, 4.8228e-04, 4.8081e-04, 4.7935e-04, 4.7789e-04,\n",
      "        4.7643e-04, 4.7500e-04, 4.7357e-04, 4.7215e-04, 4.7072e-04, 4.6933e-04,\n",
      "        4.6792e-04, 4.6652e-04, 4.6515e-04, 4.6376e-04, 4.6239e-04, 4.6104e-04,\n",
      "        4.5966e-04, 4.5831e-04, 4.5698e-04, 4.5564e-04, 4.5432e-04, 4.5299e-04,\n",
      "        4.5170e-04, 4.5038e-04, 4.4907e-04, 4.4779e-04, 4.4651e-04, 4.4524e-04,\n",
      "        4.4394e-04, 4.4269e-04, 4.4143e-04, 4.4018e-04, 4.3891e-04, 4.3769e-04,\n",
      "        4.3644e-04, 4.3523e-04, 4.3400e-04, 4.3279e-04, 4.3158e-04, 4.3038e-04,\n",
      "        4.2916e-04, 4.2797e-04, 4.2681e-04, 4.2563e-04, 4.2446e-04, 4.2330e-04,\n",
      "        4.2213e-04, 4.2097e-04, 4.1982e-04, 4.1868e-04, 4.1754e-04, 4.1640e-04,\n",
      "        4.1528e-04, 4.1416e-04, 4.1307e-04, 4.1192e-04, 4.1082e-04, 4.0973e-04,\n",
      "        4.0863e-04, 4.0753e-04, 4.0647e-04, 4.0540e-04, 4.0430e-04, 4.0325e-04,\n",
      "        4.0218e-04, 4.0112e-04, 4.0006e-04, 3.9903e-04, 3.9799e-04, 3.9693e-04,\n",
      "        3.9589e-04, 3.9488e-04, 3.9385e-04, 3.9285e-04, 3.9182e-04, 3.9081e-04,\n",
      "        3.8980e-04, 3.8880e-04, 3.8781e-04, 3.8681e-04, 3.8584e-04, 3.8486e-04,\n",
      "        3.8388e-04, 3.8292e-04, 3.8193e-04, 3.8099e-04, 3.8002e-04, 3.7906e-04,\n",
      "        3.7812e-04, 3.7718e-04, 3.7622e-04, 3.7528e-04, 3.7436e-04, 3.7344e-04,\n",
      "        3.7251e-04, 3.7158e-04, 3.7067e-04, 3.6975e-04, 3.6885e-04, 3.6794e-04,\n",
      "        3.6704e-04, 3.6616e-04, 3.6525e-04, 3.6437e-04, 3.6349e-04, 3.6261e-04,\n",
      "        3.6171e-04, 3.6085e-04, 3.5999e-04, 3.5913e-04, 3.5826e-04, 3.5741e-04,\n",
      "        3.5654e-04, 3.5570e-04, 3.5485e-04, 3.5402e-04, 3.5318e-04, 3.5235e-04,\n",
      "        3.5152e-04, 3.5069e-04, 3.4984e-04, 3.4904e-04, 3.4822e-04, 3.4742e-04,\n",
      "        3.4659e-04, 3.4580e-04, 3.4499e-04, 3.4420e-04, 3.4340e-04, 3.4259e-04,\n",
      "        3.4179e-04, 3.4102e-04, 3.4023e-04, 3.3945e-04, 3.3868e-04, 3.3790e-04,\n",
      "        3.3713e-04, 3.3636e-04, 3.3560e-04, 3.3484e-04, 3.3408e-04, 3.3332e-04,\n",
      "        3.3259e-04, 3.3183e-04, 3.3110e-04, 3.3033e-04, 3.2960e-04, 3.2887e-04,\n",
      "        3.2812e-04, 3.2740e-04, 3.2667e-04, 3.2594e-04, 3.2523e-04, 3.2452e-04,\n",
      "        3.2380e-04, 3.2307e-04, 3.2237e-04, 3.2167e-04, 3.2095e-04, 3.2025e-04,\n",
      "        3.1956e-04, 3.1887e-04, 3.1817e-04, 3.1748e-04, 3.1680e-04, 3.1612e-04,\n",
      "        3.1543e-04, 3.1473e-04, 3.1408e-04, 3.1341e-04, 3.1273e-04, 3.1207e-04,\n",
      "        3.1139e-04, 3.1072e-04, 3.1008e-04, 3.0940e-04, 3.0876e-04, 3.0810e-04,\n",
      "        3.0745e-04, 3.0681e-04, 3.0615e-04, 3.0551e-04, 3.0487e-04, 3.0424e-04,\n",
      "        3.0360e-04, 3.0296e-04, 3.0233e-04, 3.0171e-04, 3.0107e-04, 3.0045e-04,\n",
      "        2.9981e-04, 2.9921e-04, 2.9859e-04, 2.9795e-04, 2.9737e-04, 2.9676e-04,\n",
      "        2.9614e-04, 2.9554e-04, 2.9493e-04, 2.9434e-04, 2.9373e-04, 2.9314e-04,\n",
      "        2.9254e-04, 2.9195e-04, 2.9135e-04, 2.9078e-04, 2.9019e-04, 2.8959e-04,\n",
      "        2.8903e-04, 2.8845e-04, 2.8787e-04, 2.8729e-04, 2.8673e-04, 2.8614e-04,\n",
      "        2.8558e-04, 2.8503e-04, 2.8444e-04, 2.8388e-04, 2.8333e-04, 2.8277e-04,\n",
      "        2.8220e-04, 2.8167e-04, 2.8109e-04, 2.8055e-04, 2.7999e-04, 2.7946e-04,\n",
      "        2.7890e-04, 2.7836e-04, 2.7782e-04, 2.7729e-04, 2.7675e-04, 2.7621e-04,\n",
      "        2.7569e-04, 2.7515e-04, 2.7462e-04, 2.7409e-04, 2.7357e-04, 2.7304e-04,\n",
      "        2.7252e-04, 2.7199e-04, 2.7148e-04, 2.7096e-04, 2.7045e-04, 2.6993e-04,\n",
      "        2.6944e-04, 2.6892e-04, 2.6840e-04, 2.6790e-04, 2.6739e-04, 2.6689e-04,\n",
      "        2.6639e-04, 2.6590e-04, 2.6538e-04, 2.6489e-04, 2.6441e-04, 2.6391e-04,\n",
      "        2.6343e-04, 2.6294e-04, 2.6244e-04, 2.6197e-04, 2.6148e-04, 2.6100e-04,\n",
      "        2.6050e-04, 2.6004e-04, 2.5957e-04, 2.5908e-04, 2.5861e-04, 2.5814e-04,\n",
      "        2.5764e-04, 2.5719e-04, 2.5674e-04, 2.5625e-04, 2.5579e-04, 2.5532e-04,\n",
      "        2.5487e-04, 2.5441e-04, 2.5394e-04, 2.5349e-04, 2.5304e-04, 2.5259e-04,\n",
      "        2.5213e-04, 2.5166e-04, 2.5122e-04, 2.5078e-04, 2.5032e-04, 2.4988e-04,\n",
      "        2.4944e-04, 2.4901e-04, 2.4856e-04, 2.4812e-04, 2.4768e-04, 2.4724e-04,\n",
      "        2.4682e-04, 2.4638e-04, 2.4594e-04, 2.4551e-04, 2.4507e-04, 2.4466e-04,\n",
      "        2.4422e-04, 2.4380e-04, 2.4339e-04, 2.4294e-04, 2.4253e-04, 2.4211e-04,\n",
      "        2.4168e-04, 2.4125e-04, 2.4083e-04, 2.4045e-04, 2.4002e-04, 2.3962e-04,\n",
      "        2.3917e-04, 2.3878e-04, 2.3839e-04, 2.3797e-04, 2.3757e-04, 2.3716e-04,\n",
      "        2.3674e-04, 2.3634e-04, 2.3597e-04, 2.3554e-04, 2.3515e-04, 2.3477e-04,\n",
      "        2.3438e-04, 2.3397e-04, 2.3357e-04, 2.3317e-04, 2.3278e-04, 2.3240e-04,\n",
      "        2.3201e-04, 2.3163e-04, 2.3124e-04, 2.3085e-04, 2.3047e-04, 2.3008e-04,\n",
      "        2.2969e-04, 2.2933e-04, 2.2894e-04, 2.2857e-04, 2.2819e-04, 2.2782e-04,\n",
      "        2.2745e-04, 2.2706e-04, 2.2668e-04, 2.2632e-04, 2.2597e-04, 2.2558e-04,\n",
      "        2.2522e-04, 2.2486e-04, 2.2447e-04, 2.2412e-04, 2.2375e-04, 2.2340e-04,\n",
      "        2.2303e-04, 2.2266e-04, 2.2229e-04, 2.2194e-04, 2.2159e-04, 2.2123e-04,\n",
      "        2.2086e-04, 2.2051e-04, 2.2015e-04, 2.1982e-04, 2.1947e-04, 2.1912e-04,\n",
      "        2.1877e-04, 2.1841e-04, 2.1807e-04, 2.1773e-04, 2.1738e-04, 2.1703e-04,\n",
      "        2.1669e-04, 2.1636e-04, 2.1602e-04, 2.1567e-04, 2.1534e-04, 2.1498e-04,\n",
      "        2.1466e-04, 2.1433e-04, 2.1398e-04, 2.1365e-04, 2.1332e-04, 2.1299e-04,\n",
      "        2.1265e-04, 2.1232e-04, 2.1199e-04, 2.1167e-04, 2.1134e-04, 2.1100e-04,\n",
      "        2.1066e-04, 2.1036e-04, 2.1002e-04, 2.0971e-04, 2.0938e-04, 2.0907e-04,\n",
      "        2.0874e-04, 2.0843e-04, 2.0812e-04, 2.0779e-04, 2.0748e-04, 2.0717e-04,\n",
      "        2.0684e-04, 2.0653e-04, 2.0622e-04, 2.0589e-04, 2.0559e-04, 2.0528e-04,\n",
      "        2.0497e-04, 2.0467e-04, 2.0437e-04, 2.0404e-04, 2.0375e-04, 2.0344e-04,\n",
      "        2.0313e-04, 2.0281e-04, 2.0251e-04, 2.0222e-04, 2.0191e-04, 2.0162e-04,\n",
      "        2.0132e-04, 2.0101e-04, 2.0072e-04, 2.0042e-04, 2.0013e-04, 1.9983e-04,\n",
      "        1.9954e-04, 1.9923e-04, 1.9895e-04, 1.9866e-04, 1.9838e-04, 1.9807e-04,\n",
      "        1.9778e-04, 1.9749e-04, 1.9721e-04, 1.9690e-04, 1.9663e-04, 1.9634e-04,\n",
      "        1.9605e-04, 1.9578e-04, 1.9548e-04, 1.9519e-04, 1.9492e-04, 1.9464e-04,\n",
      "        1.9436e-04, 1.9409e-04, 1.9381e-04, 1.9354e-04, 1.9323e-04, 1.9296e-04,\n",
      "        1.9268e-04, 1.9241e-04, 1.9214e-04, 1.9186e-04, 1.9158e-04, 1.9132e-04,\n",
      "        1.9104e-04, 1.9077e-04, 1.9050e-04, 1.9023e-04, 1.8997e-04, 1.8970e-04,\n",
      "        1.8941e-04, 1.8913e-04, 1.8888e-04, 1.8862e-04, 1.8837e-04, 1.8809e-04,\n",
      "        1.8782e-04, 1.8756e-04, 1.8731e-04, 1.8706e-04, 1.8678e-04, 1.8654e-04,\n",
      "        1.8625e-04, 1.8600e-04, 1.8575e-04, 1.8549e-04, 1.8522e-04, 1.8498e-04,\n",
      "        1.8472e-04, 1.8447e-04, 1.8419e-04, 1.8395e-04, 1.8370e-04, 1.8344e-04,\n",
      "        1.8321e-04, 1.8293e-04, 1.8268e-04, 1.8242e-04, 1.8219e-04, 1.8194e-04,\n",
      "        1.8169e-04, 1.8146e-04, 1.8120e-04, 1.8096e-04, 1.8070e-04, 1.8045e-04,\n",
      "        1.8020e-04, 1.7998e-04, 1.7973e-04, 1.7948e-04, 1.7924e-04, 1.7899e-04,\n",
      "        1.7876e-04, 1.7852e-04, 1.7829e-04, 1.7805e-04, 1.7780e-04, 1.7757e-04,\n",
      "        1.7732e-04, 1.7709e-04, 1.7685e-04, 1.7662e-04, 1.7640e-04, 1.7615e-04,\n",
      "        1.7591e-04, 1.7568e-04, 1.7545e-04, 1.7522e-04, 1.7497e-04, 1.7474e-04,\n",
      "        1.7453e-04, 1.7429e-04, 1.7406e-04, 1.7384e-04, 1.7360e-04, 1.7337e-04,\n",
      "        1.7317e-04, 1.7292e-04, 1.7271e-04, 1.7246e-04, 1.7223e-04, 1.7203e-04,\n",
      "        1.7181e-04, 1.7157e-04, 1.7136e-04, 1.7112e-04, 1.7090e-04, 1.7069e-04,\n",
      "        1.7046e-04, 1.7025e-04, 1.7003e-04, 1.6981e-04, 1.6959e-04, 1.6936e-04,\n",
      "        1.6915e-04, 1.6893e-04, 1.6871e-04, 1.6851e-04, 1.6828e-04, 1.6807e-04,\n",
      "        1.6786e-04, 1.6763e-04, 1.6743e-04, 1.6721e-04, 1.6700e-04, 1.6677e-04,\n",
      "        1.6658e-04, 1.6636e-04, 1.6615e-04, 1.6594e-04, 1.6574e-04, 1.6551e-04,\n",
      "        1.6532e-04, 1.6512e-04, 1.6490e-04, 1.6469e-04, 1.6449e-04, 1.6428e-04,\n",
      "        1.6408e-04, 1.6386e-04, 1.6365e-04, 1.6348e-04])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(torch.tensor(model_losses).detach())\n",
    "plt.plot(torch.tensor(model_losses).detach()[:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "naval-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1333, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(torch.tensor(model_accuracies).detach())\n",
    "plt.plot(torch.tensor(model_accuracies).detach()[:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-florist",
   "metadata": {},
   "source": [
    "# Train ReLU net with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "medical-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, dim_vector[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[1], dim_vector[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[2], dim_vector[3]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[3],num_samples)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "developing-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.100229, Accuracy 0.333333\n",
      "Epoch 500, Loss 0.000583, Accuracy 1.000000\n",
      "Epoch 1000, Loss 0.000230, Accuracy 1.000000\n"
     ]
    }
   ],
   "source": [
    "relu_model_trained, relu_model_losses, relu_model_accuracies = ce_training_loop(\n",
    "    n_epochs = 1000, \n",
    "    learning_rate = 0.05,\n",
    "    model = relu_net,\n",
    "    params = list(relu_net.parameters()),\n",
    "    x_train = noisy_threes_flat,\n",
    "    y_train = noisy_labels,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "heard-palestine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8e6fcab8e0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(relu_model_losses).detach()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "changed-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_both(num_samples, m_copies, dim_vector, label=3):\n",
    "    noisy_threes, noisy_labels = add_noise(label=3, n=int(num_samples), m=int(m_copies), verbose =False)\n",
    "    noisy_threes_flat = noisy_threes.flatten(1)\n",
    "    \n",
    "    print('')\n",
    "    print('### Data description')\n",
    "    print('number or original images =', num_samples)\n",
    "    print('number of copies of each =', m_copies)\n",
    "    print('dimension vector =', dim_vector)\n",
    "    print('')\n",
    "    \n",
    "    print('#### Training stepReLU radnet:')\n",
    "    radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False)\n",
    "    model_trained, model_losses = training_loop(\n",
    "        n_epochs = 2000, \n",
    "        learning_rate = 0.05,\n",
    "        model = radnet,\n",
    "        params = list(radnet.parameters()),\n",
    "        x_train = noisy_threes_flat,\n",
    "        y_train = noisy_labels,\n",
    "        verbose=True)\n",
    "    \n",
    "    relu_net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(28*28, dim_vector[1]),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(dim_vector[1], dim_vector[2]),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(dim_vector[2], dim_vector[3]),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(dim_vector[3],num_samples)\n",
    "        )\n",
    "    \n",
    "    print('')\n",
    "    print('#### Training ReLU MLP:')\n",
    "    \n",
    "    relu_model_trained, relu_model_losses = training_loop(\n",
    "        n_epochs = 2000, \n",
    "        learning_rate = 0.05,\n",
    "        model = relu_net,\n",
    "        params = list(relu_net.parameters()),\n",
    "        x_train = noisy_threes_flat,\n",
    "        y_train = noisy_labels,\n",
    "        verbose=True)\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "written-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.137116432189941, 10.164294242858887, 8.137116432189941]\n",
      "tensor(0.1438, dtype=torch.float64) tensor(-0.1256, dtype=torch.float64)\n",
      "\n",
      "### Data description\n",
      "number or original images = 3\n",
      "number of copies of each = 10\n",
      "dimension vector = [784, 785, 786, 3]\n",
      "\n",
      "#### Training stepReLU radnet:\n",
      "Epoch 1, Loss 0.347070\n",
      "Epoch 500, Loss 0.000000\n",
      "Epoch 1000, Loss 0.000000\n",
      "Epoch 1500, Loss 0.000000\n",
      "Epoch 2000, Loss 0.000000\n",
      "\n",
      "#### Training ReLU MLP:\n",
      "Epoch 1, Loss 0.600010\n",
      "Epoch 500, Loss 0.001136\n",
      "Epoch 1000, Loss 0.000002\n",
      "Epoch 1500, Loss 0.000000\n",
      "Epoch 2000, Loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "train_both(\n",
    "    num_samples = 3,\n",
    "    m_copies = 10,\n",
    "    dim_vector= [28*28, 28*28 + 1, 28*28 + 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "horizontal-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [3]\n",
    "ms = [1000]\n",
    "d= 28*28\n",
    "dim_vec = [d, d+1, d+2, d+3, 3]\n",
    "\n",
    "# 10 runs for each, use seed for reproducibility\n",
    "\n",
    "# Desired metric: mean square error or accuracy (search pytorch metric accuracy)\n",
    "# Maybe use cross entropy instead of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "m=1000\n",
    "# test a bunch of different rates for each of radnet, relu MLP\n",
    "# the \"optimal\" learning rate for the radnet and relu could be different\n",
    "\n",
    "# Hyperparameter search for the learning rate\n",
    "\n",
    "# If the accuracy of both is the same, can look at the rate of convergence (eyeballing the plot) with optimized learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalization\n",
    "\n",
    "n = 3\n",
    "m=1000 + 1000\n",
    "\n",
    "# split training and test set, equal numbers of each\n",
    "\n",
    "# Use best learning rate for each radnet, relu MLP\n",
    "# Compare the test set loss and accuracy for each, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [3,4,5]\n",
    "ms = [100,500,1000,10000]\n",
    "d= 28*28\n",
    "dim_vecs = [\n",
    "    [d, d+1, d+2, d+3, 1],\n",
    "    [d, d+1, d+2, d+3, d+4, 1],\n",
    "    [d, d+1, d+2, d+3, d+4, d+5, 1]]\n",
    "\n",
    "# 12 combinations, and do 10 runs for each\n",
    "\n",
    "# Desired metric: mean square error or accuracy\n",
    "# Maybe use cross entropy instead of MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-stranger",
   "metadata": {},
   "source": [
    "Change data set:\n",
    "\n",
    "* overlap circles\n",
    "* choose one sample from each MNIST label (0-9), or just 0,1,2,3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-dynamics",
   "metadata": {},
   "source": [
    "Change model:\n",
    "\n",
    "* if the models are tied, can make the problem harder by reducing the number of parameters (or doing the data set changes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-vermont",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if False:\n",
    "    for i in range(len(n)):\n",
    "        for m in ms:\n",
    "            train_both(\n",
    "                num_samples = n[i],\n",
    "                m_copies = m,\n",
    "                dim_vector= dims[i])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-arrangement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-death",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "differential-jacket",
   "metadata": {},
   "source": [
    "# Network for learning all of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_flat = train_features.flatten(1)\n",
    "train_features_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape\n",
    "train_labels_onehot = F.one_hot(train_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "radnet = RadNet(eta=torch.sigmoid, dims=[28*28,28*28, 28 , 28,10], has_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained, model_losses = training_loop(\n",
    "    n_epochs = 3000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = train_features_flat,\n",
    "    y_train = train_labels_onehot,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 28*28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28*28, 28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28, 28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model_trained, relu_model_losses = training_loop(\n",
    "    n_epochs = 3000, \n",
    "    learning_rate = 0.05,\n",
    "    model = relu_net,\n",
    "    params = list(relu_net.parameters()),\n",
    "    x_train = train_features_flat,\n",
    "    y_train = train_labels_onehot,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-pendant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-royalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-exhaust",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-deadline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-adult",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-raise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-recorder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "laughing-yesterday",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-expression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "radius = float('inf')\n",
    "for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "        if torch.linalg.norm(threes[i] - threes[j]).item() < radius:\n",
    "            radius = torch.linalg.norm(threes[i] - threes[j]).item()\n",
    "radius = radius/2.5\n",
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_threes = torch.Tensor(torch.Size([int(n*m), 1, 28, 28]))\n",
    "noisy_labels = torch.Tensor(torch.Size([n*m, n]))\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        noisy_threes[i*n + j]= threes[i] + noise[j]   \n",
    "        noisy_labels[i*m + j]=  torch.eye(n)[i]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-shoot",
   "metadata": {},
   "source": [
    "if False:\n",
    "    print(noisy_threes.shape, noisy_labels.shape)\n",
    "if False:\n",
    "    plt.imshow(threes[0][0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(noisy_threes[0][0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(noisy_threes[1][0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
