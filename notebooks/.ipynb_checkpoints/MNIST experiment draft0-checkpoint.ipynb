{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advanced-proportion",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-d78369e25278>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-d78369e25278>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    from ../source import *\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import (Dataset, TensorDataset, DataLoader)\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from ../source import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-azerbaijan",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step RelU\n",
    "# Version for the eta in the definition of a radial rescaling activation\n",
    "\n",
    "def stepReLU_eta(r):\n",
    "    if r.shape == torch.Size([]):\n",
    "        if r < 1:\n",
    "            return 1e-6\n",
    "        return r\n",
    "    else:\n",
    "        for i in range(len(r)):\n",
    "            if r[i] < 1:\n",
    "                r[i] = 1e-6\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create uniform random noise in the unit d-ball\n",
    "def generate_noise(m, r, d=28*28):\n",
    "    '''m is the number of samples, r is the radius\n",
    "    d is the total dimension, which is 28*28 for MNIST'''\n",
    "    \n",
    "    u = np.random.multivariate_normal(np.zeros(d),np.eye(d),m)  # an array of d normally distributed random variables\n",
    "    norm=np.sum(u**2, axis = 1) **(0.5)\n",
    "    norm = norm.reshape(m,1)\n",
    "    rands = np.random.uniform(size=m)**(1.0/d)\n",
    "    rands = rands.reshape(m,1)\n",
    "    return r*rands*u/norm\n",
    "\n",
    "# Note: need to do the following before adding to a sample:\n",
    "# torch.tensor(generate_noise(m,radius,d)).reshape(m,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "def smallest_distance(x: torch.tensor) -> float:\n",
    "    radius = float('inf')\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i):\n",
    "            if torch.linalg.norm(x[i] - x[j]).item() < radius:\n",
    "                radius = torch.linalg.norm(x[i] - x[j]).item()\n",
    "    return radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "def shortest_distances(x: torch.tensor) -> list:\n",
    "    result = []\n",
    "    for i in range(len(x)):\n",
    "        radius = float('inf')\n",
    "        for j in range(i):\n",
    "            if torch.linalg.norm(x[i] - x[j]).item() < radius:\n",
    "                radius = torch.linalg.norm(x[i] - x[j]).item()\n",
    "        for j in range(i+1,len(x)):\n",
    "            if torch.linalg.norm(x[i] - x[j]).item() < radius:\n",
    "                radius = torch.linalg.norm(x[i] - x[j]).item()\n",
    "        result.append(radius)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_distances(torch.tensor([3.,5.,9.,29., 2.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-finder",
   "metadata": {},
   "source": [
    "# Get MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(mnist_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "if False:\n",
    "    img = train_features[0].squeeze()\n",
    "    label = train_labels[0]\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-offering",
   "metadata": {},
   "source": [
    "# Select threes and add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(label=None, n=5, m=100, noise_scale=0.5, noise_type='ball', use_labels=False, verbose=False):\n",
    "    '''label is one of 0,1,2,3,4,5,6,7,8,9;\n",
    "    n is the number of original images; \n",
    "    m is the number of noisy samples per original image;\n",
    "    may want to make the 2.5 definition of the radius into a hyperparameter\n",
    "    '''\n",
    "    \n",
    "    batch_size = n * (1 if label is None else 20)\n",
    "    train_dataloader = DataLoader(mnist_dataset, batch_size, shuffle=True)\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "    # Get a selection of data with the same label, crop it to size n\n",
    "    if label is not None:\n",
    "        which = train_labels == label\n",
    "        selection = train_features[which]\n",
    "        labels    = train_labels[which]\n",
    "    else:\n",
    "        selection = train_features\n",
    "        labels    = train_labels\n",
    "    # randomly pick n elements\n",
    "    which = torch.randperm(len(selection))[:n]\n",
    "    selection = selection[which]\n",
    "    labels    = labels[which]\n",
    "    #selection = selection[:n]\n",
    "    assert selection.shape[0] == n, \"Too few of this label; take another batch\"\n",
    "    if verbose:\n",
    "        plt.imshow(selection[2].squeeze(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "    \n",
    "    #global radii, noise, noise_samples, noisy_labels\n",
    "    radii = shortest_distances(selection)\n",
    "    if noise_type == 'ball':\n",
    "        noise = torch.tensor(generate_noise(m,r=1,d=28*28)).reshape(m,1,28,28)\n",
    "    elif noise_type == 'normal':\n",
    "        noise = torch.randn((m,1,28,28)) / np.sqrt(28*28)\n",
    "    else:\n",
    "        raise Exception(f'Unknown noise_type: {noise_type}')\n",
    "    \n",
    "    noisy_samples = torch.Tensor(torch.Size([int(n*m), 1, 28, 28]))\n",
    "    noisy_labels = torch.Tensor(torch.Size([n*m])).to(torch.int64)\n",
    "    for i in range(n):\n",
    "        radius = radii[i] * noise_scale\n",
    "        #print(f'Radius: {radius}')\n",
    "        assert radius > 1e-6, \"some samples are too close together\"\n",
    "        for j in range(m):\n",
    "            noisy_samples[i*m + j] = selection[i] + radius*noise[j]\n",
    "            if use_labels:\n",
    "                label = labels[i]\n",
    "            else:\n",
    "                label = i\n",
    "            noisy_labels[i*m + j] = label\n",
    "    if use_labels:\n",
    "        num_classes = 10\n",
    "    else:\n",
    "        num_classes = n\n",
    "    noisy_labels = torch.nn.functional.one_hot(noisy_labels, num_classes).to(torch.float32)\n",
    "    \n",
    "    if verbose:\n",
    "        plt.imshow(selection[0][0], cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(noisy_samples[0][0], cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(noisy_samples[1][0], cmap=\"gray\")\n",
    "    \n",
    "    return noisy_samples, noisy_labels\n",
    "\n",
    "def noisy_mnist_dataset(device=None, **kwargs):\n",
    "    noisy_samples, noisy_labels = add_noise(**kwargs)\n",
    "    return TensorDataset(noisy_samples.flatten(1).to(device), noisy_labels.to(device))\n",
    "\n",
    "# Alternative for the labels:\n",
    "# torch.eye(n).repeat_interleave(m, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print('Enter the number of original images:')\n",
    "    num_samples = input()\n",
    "\n",
    "    print('Enter the number of noisy copies of each:')\n",
    "    m_copies = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "m_copies = 10\n",
    "\n",
    "noisy_threes, noisy_labels = add_noise(label=3, n=int(num_samples), m=int(m_copies), verbose = True, noise_scale=2, noise_type='normal')\n",
    "print(noisy_threes.shape, noisy_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_threes, noisy_labels = add_noise(label=3, n=int(num_samples), m=int(m_copies), verbose = True, noise_scale=2, noise_type='ball')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_threes_flat = noisy_threes.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = noisy_mnist_dataset()\n",
    "loader = DataLoader(data, batch_size=len(data))\n",
    "for x,y in loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-uganda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "threaded-october",
   "metadata": {},
   "source": [
    "# Train radnet with the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=28*28\n",
    "dim_vector = [d, d+1, d+2, d+3, num_samples]\n",
    "\n",
    "# torch.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False).to('cpu')\n",
    "model_trained, model_losses = training_loop(\n",
    "    n_epochs = 2000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = noisy_threes_flat,\n",
    "    y_train = noisy_labels,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda')\n",
    "print(f'Running on {device}')\n",
    "radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False).to(device)\n",
    "model_trained, model_losses = training_loop(\n",
    "    n_epochs = 2000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = noisy_threes_flat.to(device),\n",
    "    y_train = noisy_labels.to(device),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-florist",
   "metadata": {},
   "source": [
    "# Train ReLU net with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, dim_vector[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[1], dim_vector[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[2], dim_vector[3]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[3],num_samples)\n",
    "    )\n",
    "print(relu_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model_trained, relu_model_losses = training_loop(\n",
    "    n_epochs = 2000, \n",
    "    learning_rate = 0.05,\n",
    "    model = relu_net,\n",
    "    params = list(relu_net.parameters()),\n",
    "    x_train = noisy_threes_flat,\n",
    "    y_train = noisy_labels,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(model_losses).detach())\n",
    "plt.plot(torch.tensor(relu_model_losses).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, loss_fn=torch.nn.CrossEntropyLoss()):\n",
    "    with torch.no_grad():\n",
    "        loss_sum = 0.0\n",
    "        accuracy_sum = 0.0\n",
    "        for x, y in test_data:\n",
    "            y_pred = model(x) \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            pred_class = torch.argmax(y_pred, dim=1)\n",
    "            actual_class = torch.argmax(y, dim=1)\n",
    "            accuracy = torch.mean((pred_class == actual_class).to(float))\n",
    "            loss_sum += loss.detach().cpu()\n",
    "            accuracy_sum += accuracy.detach().cpu()\n",
    "        return loss_sum, accuracy_sum\n",
    "            \n",
    "def training_loop(n_epochs, learning_rate, model, train_data, test_data=None, verbose=True, loss_fn=torch.nn.CrossEntropyLoss()):\n",
    "    model.train(True)\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_sum = 0.0\n",
    "        accuracy_sum = 0.0\n",
    "        for x, y in train_data:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            y_pred = model(x) \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_class = torch.argmax(y_pred, dim=1)\n",
    "                actual_class = torch.argmax(y, dim=1)\n",
    "                accuracy = torch.mean((pred_class == actual_class).to(float))\n",
    "                loss_sum += loss.detach().cpu()\n",
    "                accuracy_sum += accuracy.detach().cpu()\n",
    "        \n",
    "        losses.append(loss_sum)\n",
    "        accuracies.append(accuracy_sum)\n",
    "        if verbose:\n",
    "            if epoch ==1 or epoch % 500 == 0:\n",
    "                if test_data is not None:\n",
    "                    test_loss, test_accuracy = test(model, test_data)\n",
    "                print('Epoch %d, Loss %f, Accuracy %f, Test loss %f, Test accuracy %f' % (epoch, loss_sum, accuracy_sum, test_loss, test_accuracy))\n",
    "\n",
    "    return {'model':model, 'loss':losses, 'accuracy':accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLUNet(dims):\n",
    "    \"\"\"Build a ReLU network with the given layer sizes. There is a ReLU between each pair of linear layers.\"\"\"\n",
    "    layers = []\n",
    "    for i in range(len(dims) - 1):\n",
    "        layers.append(torch.nn.Linear(dims[i], dims[i+1]))\n",
    "        if i+1 < len(dims):\n",
    "            layers.append(torch.nn.ReLU())\n",
    "    return torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_both(num_samples, m_copies, dim_vector=None, label=3, device=device, batch_size=None, epochs=2000, loss_fn=torch.nn.CrossEntropyLoss(), train_fraction=0.8, **kwargs):\n",
    "    data = noisy_mnist_dataset(label=None, n=int(num_samples), m=int(m_copies),\n",
    "                               verbose=False, device=device, **kwargs)\n",
    "    #noisy_threes, noisy_labels = add_noise(label=3, n=int(num_samples), m=int(m_copies),\n",
    "    #                                       verbose=False, noise_scale=noise_scale, noise_type=noise_type)\n",
    "    #noisy_threes_flat = noisy_threes.flatten(1).to(device)\n",
    "    #noisy_labels = noisy_labels.to(device)\n",
    "    num_train = int(len(data)*train_fraction)\n",
    "    train_data, test_data = torch.utils.data.random_split(data, [num_train, len(data)- num_train])\n",
    "    if batch_size is None:\n",
    "        batch_size = len(train_data)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_loader  = DataLoader(test_data, batch_size=len(test_data))\n",
    "    num_classes = next(iter(train_data))[1].shape[-1]\n",
    "    if dim_vector is None:\n",
    "        dim_vector= [28*28, 28*28 + 1, 28*28 + 2, num_classes]\n",
    "    \n",
    "    print('')\n",
    "    print('### Data description')\n",
    "    print('number or original images =', num_samples)\n",
    "    print('number of copies of each =', m_copies)\n",
    "    print('number of classes =', num_classes)\n",
    "    print('number or samples =', len(train_data),\"train,\", len(test_data),\"test\")\n",
    "    print('dimension vector =', dim_vector)\n",
    "    print('')\n",
    "    \n",
    "    print('#### Training stepReLU radnet:')\n",
    "    radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False).to(device)\n",
    "    log = training_loop(\n",
    "        n_epochs = epochs, \n",
    "        learning_rate = 0.01,\n",
    "        model = radnet,\n",
    "        train_data=train_loader,\n",
    "        test_data=test_loader,\n",
    "        loss_fn = loss_fn,\n",
    "        verbose=True)\n",
    "    \n",
    "    print('')\n",
    "    print('#### Training ReLU MLP:')\n",
    "    relu_net = ReLUNet(dim_vector).to(device)\n",
    "    relu_log = training_loop(\n",
    "        n_epochs = epochs, \n",
    "        learning_rate = 0.01,\n",
    "        model = relu_net,\n",
    "        train_data=train_loader,\n",
    "        test_data=test_loader,\n",
    "        loss_fn = loss_fn,\n",
    "        verbose=True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_both(\n",
    "    num_samples = 500,\n",
    "    m_copies = 1,\n",
    "    noise_scale = 1.0,\n",
    "    noise_type = 'normal',\n",
    "    epochs = 5000,\n",
    "    #loss_fn = torch.nn.MSELoss()\n",
    "    use_labels = True,\n",
    "    batch_size = 100,\n",
    "    #dim_vector = [784, 785, 10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_both(\n",
    "    num_samples = 500,\n",
    "    m_copies = 10,\n",
    "    noise_scale = 1.0,\n",
    "    noise_type = 'normal',\n",
    "    #loss_fn = torch.nn.MSELoss()\n",
    "    use_labels = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [3,4,5]\n",
    "ms = [100,500,1000]\n",
    "d= 28*28\n",
    "dim_vecs = [\n",
    "    [d, d+1, d+2, d+3, 1],\n",
    "    [d, d+1, d+2, d+3, d+4, 1],\n",
    "    [d, d+1, d+2, d+3, d+4, d+5, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    for i in range(len(n)):\n",
    "        for m in ms:\n",
    "            train_both(\n",
    "                num_samples = n[i],\n",
    "                m_copies = m,\n",
    "                dim_vector= dims[i])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-arrangement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-death",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "differential-jacket",
   "metadata": {},
   "source": [
    "# Network for learning all of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_flat = train_features.flatten(1)\n",
    "train_features_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "radnet = RadNet(eta=torch.sigmoid, dims=[28*28,28*28, 28 , 28,1], has_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained, model_losses = training_loop(\n",
    "    n_epochs = 3000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = train_features_flat,\n",
    "    y_train = train_labels,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-debut",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-pendant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-royalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-exhaust",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-deadline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-adult",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-raise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-recorder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "laughing-yesterday",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-expression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "radius = float('inf')\n",
    "for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "        if torch.linalg.norm(threes[i] - threes[j]).item() < radius:\n",
    "            radius = torch.linalg.norm(threes[i] - threes[j]).item()\n",
    "radius = radius/2.5\n",
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_threes = torch.Tensor(torch.Size([int(n*m), 1, 28, 28]))\n",
    "noisy_labels = torch.Tensor(torch.Size([n*m, n]))\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        noisy_threes[i*n + j]= threes[i] + noise[j]   \n",
    "        noisy_labels[i*m + j]=  torch.eye(n)[i]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-shoot",
   "metadata": {},
   "source": [
    "if False:\n",
    "    print(noisy_threes.shape, noisy_labels.shape)\n",
    "if False:\n",
    "    plt.imshow(threes[0][0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(noisy_threes[0][0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(noisy_threes[1][0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
