{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from statistics import mean, stdev\n",
    "\n",
    "from source import *\n",
    "from MNIST_source import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of original images\n",
    "n = 3\n",
    "# Number of noisy samples for each original sample\n",
    "m = 10\n",
    "# Widths of both neural networks\n",
    "widths = [28*28, 28*28 + 1, 28*28 + 2, n]\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "num_trials = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "radnet_final_losses = []\n",
    "radnet_final_accuracies = []\n",
    "\n",
    "relunet_final_losses = []\n",
    "relunet_final_accuracies = []\n",
    "\n",
    "for trial in tqdm(range(num_trials)):\n",
    "        rad_los, rad_acc, relu_los, relu_acc = train_both(\n",
    "            num_samples = n,\n",
    "            m_copies = m,\n",
    "            dim_vector= widths,\n",
    "            verbose=False,\n",
    "            num_epochs=num_epochs)\n",
    "        radnet_final_losses.append(round(rad_los[-1].item(),5))\n",
    "        radnet_final_accuracies.append(rad_acc[-1].item())\n",
    "        relunet_final_losses.append(round(relu_los[-1].item(),5))\n",
    "        relunet_final_accuracies.append(relu_acc[-1].item())\n",
    "\n",
    "print(\"Train both networks for %d epochs\" % num_epochs)\n",
    "print( \"Step ReLU radial network losses:\",  radnet_final_losses)\n",
    "print( \"Step ReLU radial network accuracies:\", radnet_final_accuracies)\n",
    "print(\"\")\n",
    "print( \"ReLU MLP losses:\", relunet_final_losses)\n",
    "print( \"ReLU MLP accuracies:\", relunet_final_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Over %d trials:\" % num_trials)\n",
    "\n",
    "print(\"Radnet Loss = {1:.3e} +/- {2:.3e}\".\n",
    "    format(radnet_final_losses, mean(radnet_final_losses), stdev(radnet_final_losses))\n",
    ")\n",
    "\n",
    "print(\"Radnet Accuracy = {1:.3e} +/- {2:.3e}\".\n",
    "    format(radnet_final_accuracies, mean(radnet_final_accuracies), stdev(radnet_final_accuracies))\n",
    ")\n",
    "\n",
    "\n",
    "print(\"ReLU MLP Loss = {1:.3e} +/- {2:.3e}\".\n",
    "    format(relunet_final_losses, mean(relunet_final_losses), stdev(relunet_final_losses))\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"ReLU MLP Accuracy = {1:.3e} +/- {2:.3e}\".\n",
    "    format(relunet_final_accuracies, mean(relunet_final_accuracies), stdev(relunet_final_accuracies))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-calvin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-courtesy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    radnet_final_losses.append(round(rad_los[-1].item(),5))\n",
    "    radnet_final_accuracies.append(rad_acc[-1].item())\n",
    "    relunet_final_losses.append(round(relu_los[-1].item(),5))\n",
    "    relunet_final_accuracies.append(relu_acc[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    radnet_final_losses.append(rad_los[-1])\n",
    "    radnet_final_accuracies.append(rad_acc[-1])\n",
    "    relunet_final_losses.append(relu_los[-1])\n",
    "    relunet_final_accuracies.append(relu_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-insulin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "short-governor",
   "metadata": {},
   "source": [
    "# Experiments to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [3]\n",
    "ms = [1000]\n",
    "d= 28*28\n",
    "dim_vec = [d, d+1, d+2, d+3, 3]\n",
    "\n",
    "# 10 runs for each, use seed for reproducibility\n",
    "\n",
    "# Desired metric: mean square error or accuracy (search pytorch metric accuracy)\n",
    "# Maybe use cross entropy instead of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "m=1000\n",
    "# test a bunch of different rates for each of radnet, relu MLP\n",
    "# the \"optimal\" learning rate for the radnet and relu could be different\n",
    "\n",
    "# Hyperparameter search for the learning rate\n",
    "\n",
    "# If the accuracy of both is the same, can look at the rate of convergence (eyeballing the plot) with optimized learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalization\n",
    "\n",
    "n = 3\n",
    "m=1000 + 1000\n",
    "\n",
    "# split training and test set, equal numbers of each\n",
    "\n",
    "# Use best learning rate for each radnet, relu MLP\n",
    "# Compare the test set loss and accuracy for each, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [3,4,5]\n",
    "ms = [100,500,1000,10000]\n",
    "d= 28*28\n",
    "dim_vecs = [\n",
    "    [d, d+1, d+2, d+3, 1],\n",
    "    [d, d+1, d+2, d+3, d+4, 1],\n",
    "    [d, d+1, d+2, d+3, d+4, d+5, 1]]\n",
    "\n",
    "# 12 combinations, and do 10 runs for each\n",
    "\n",
    "# Desired metric: mean square error or accuracy\n",
    "# Maybe use cross entropy instead of MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-stranger",
   "metadata": {},
   "source": [
    "Change data set:\n",
    "\n",
    "* overlap circles\n",
    "* choose one sample from each MNIST label (0-9), or just 0,1,2,3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-dynamics",
   "metadata": {},
   "source": [
    "Change model:\n",
    "\n",
    "* if the models are tied, can make the problem harder by reducing the number of parameters (or doing the data set changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-phrase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-thickness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "differential-jacket",
   "metadata": {},
   "source": [
    "# Network for learning all of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_flat = train_features.flatten(1)\n",
    "train_features_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape\n",
    "train_labels_onehot = F.one_hot(train_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "radnet = RadNet(eta=torch.sigmoid, dims=[28*28,28*28, 28 , 28,10], has_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained, model_losses = training_loop(\n",
    "    n_epochs = 3000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = train_features_flat,\n",
    "    y_train = train_labels_onehot,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 28*28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28*28, 28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28, 28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model_trained, relu_model_losses = training_loop(\n",
    "    n_epochs = 3000, \n",
    "    learning_rate = 0.05,\n",
    "    model = relu_net,\n",
    "    params = list(relu_net.parameters()),\n",
    "    x_train = train_features_flat,\n",
    "    y_train = train_labels_onehot,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-pendant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-royalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-exhaust",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-cylinder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-iraqi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-brush",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-truth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-opportunity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-calendar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "twelve-mercury",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get noisy sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-entrepreneur",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_samples = 3\n",
    "m_copies = 100\n",
    "\n",
    "noisy_threes, noisy_labels = add_noise(label=3, n=int(num_samples), m=int(m_copies), verbose =False)\n",
    "print(noisy_threes.shape, noisy_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-disaster",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "noisy_threes_flat = noisy_threes.flatten(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-october",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train radnet with the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-individual",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d=28*28\n",
    "dim_vector = [d, d+1, d+2, d+3,num_samples]\n",
    "\n",
    "radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-growing",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_trained, model_losses , model_accuracies = ce_training_loop(\n",
    "    n_epochs = 1000, \n",
    "    learning_rate = 0.05,\n",
    "    model = radnet,\n",
    "    params = list(radnet.parameters()),\n",
    "    x_train = noisy_threes_flat,\n",
    "    y_train = noisy_labels,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-sussex",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(model_losses).detach()[:20])\n",
    "plt.show()\n",
    "plt.plot(torch.tensor(model_accuracies).detach()[:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-chassis",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    radnet = RadNet(eta=stepReLU_eta, dims=dim_vector, has_bias=False).to(device) \n",
    "    model_trained, model_losses, model_accuracies = ce_training_loop(\n",
    "        n_epochs = 2000, \n",
    "        learning_rate = 0.05,\n",
    "        model = radnet,\n",
    "        params = list(radnet.parameters()),\n",
    "        x_train = noisy_threes_flat.to(device),\n",
    "        y_train = noisy_labels.to(device),\n",
    "        verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-florist",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train ReLU net with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-stage",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, dim_vector[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[1], dim_vector[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[2], dim_vector[3]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(dim_vector[3],num_samples)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-visit",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu_model_trained, relu_model_losses, relu_model_accuracies = ce_training_loop(\n",
    "    n_epochs = 1000, \n",
    "    learning_rate = 0.05,\n",
    "    model = relu_net,\n",
    "    params = list(relu_net.parameters()),\n",
    "    x_train = noisy_threes_flat,\n",
    "    y_train = noisy_labels,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-palestine",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(relu_model_losses).detach()[:20])\n",
    "plt.show()\n",
    "plt.plot(torch.tensor(relu_model_accuracies).detach()[:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-blind",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train both nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-obligation",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_both(\n",
    "    num_samples = 3,\n",
    "    m_copies = 10,\n",
    "    dim_vector= [28*28, 2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-prefix",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_both(\n",
    "    num_samples = 3,\n",
    "    m_copies = 10,\n",
    "    dim_vector= [28*28, 28*28 + 1, 28*28 + 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-vermont",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if False:\n",
    "    for i in range(len(n)):\n",
    "        for m in ms:\n",
    "            train_both(\n",
    "                num_samples = n[i],\n",
    "                m_copies = m,\n",
    "                dim_vector= dims[i])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-arrangement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-death",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-deadline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-adult",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-raise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-recorder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "laughing-yesterday",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-expression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances\n",
    "radius = float('inf')\n",
    "for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "        if torch.linalg.norm(threes[i] - threes[j]).item() < radius:\n",
    "            radius = torch.linalg.norm(threes[i] - threes[j]).item()\n",
    "radius = radius/2.5\n",
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_threes = torch.Tensor(torch.Size([int(n*m), 1, 28, 28]))\n",
    "noisy_labels = torch.Tensor(torch.Size([n*m, n]))\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        noisy_threes[i*n + j]= threes[i] + noise[j]   \n",
    "        noisy_labels[i*m + j]=  torch.eye(n)[i]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-shoot",
   "metadata": {},
   "source": [
    "if False:\n",
    "    print(noisy_threes.shape, noisy_labels.shape)\n",
    "if False:\n",
    "    plt.imshow(threes[0][0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(noisy_threes[0][0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(noisy_threes[1][0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
